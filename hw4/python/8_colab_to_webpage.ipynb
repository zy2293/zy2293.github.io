{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1cDMWdOjJ2r"
   },
   "source": [
    "This notebook (and the slides from lecture 8) will help you go straight from training a model in Colab to deploying it in a webpage with TensorFlow.js - without having to leave the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "248xIjNGCRU0"
   },
   "source": [
    "Configure this notebook to work with your GitHub account by populating these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft9uEY7UCH46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.6/site-packages (0.6.5)\n",
      "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/site-packages (from tensorflowjs) (2.8.0)\n",
      "Requirement already satisfied: numpy==1.15.1 in /usr/local/lib/python3.6/site-packages (from tensorflowjs) (1.15.1)\n",
      "Requirement already satisfied: tensorflow==1.11.0 in /usr/local/lib/python3.6/site-packages (from tensorflowjs) (1.11.0)\n",
      "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/site-packages (from tensorflowjs) (1.11.0)\n",
      "Requirement already satisfied: tensorflow-hub==0.1.1 in /usr/local/lib/python3.6/site-packages (from tensorflowjs) (0.1.1)\n",
      "Requirement already satisfied: keras==2.2.2 in /usr/local/lib/python3.6/site-packages (from tensorflowjs) (2.2.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (0.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (1.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.5 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (1.0.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.3 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (1.0.5)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (32.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (1.14.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (0.29.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (3.6.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.11.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/site-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/site-packages (from keras==2.2.2->tensorflowjs) (0.19.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0->tensorflowjs) (2.6.10)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0->tensorflowjs) (0.13)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "g4k9_Ke9CaOq"
   },
   "outputs": [],
   "source": [
    "# your github username\n",
    "USER_NAME = \"zy2293\" \n",
    "\n",
    "# the email associated with your commits\n",
    "# (may not matter if you leave it as this)\n",
    "USER_EMAIL = \"zy2293@columbia.edu\" \n",
    "\n",
    "# the user token you've created (see the lecture 8 slides for instructions)\n",
    "TOKEN = \"34b82bdf21fa201df7e6f2e9706b40938ffabafd\" \n",
    "\n",
    "# site name\n",
    "# for example, if my user_name is \"foo\", then this notebook will create\n",
    "# a site at https://foo.github.io/hw4/\n",
    "SITE_NAME = \"hw4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnPqmO8vDDwW"
   },
   "source": [
    "Next, run this cell to configure git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Q0IMoqVdCIb4"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email {USER_NAME}\n",
    "!git config --global user.name  {USER_EMAIL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYfDxuMfDVas"
   },
   "source": [
    "Clone your GitHub pages repo (see the lecture 8 slides for instructions on how to create one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRUyZiFqDUxt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "repo_path = USER_NAME + '.github.io'\n",
    "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
    "  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qu4OA27iDU0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir(repo_path)\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KgISB_cAHPIs"
   },
   "source": [
    "Create a folder for your site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UAA6t4slF0nB"
   },
   "outputs": [],
   "source": [
    "project_path = os.path.join(os.getcwd(), SITE_NAME)\n",
    "if not os.path.exists(project_path): \n",
    "  os.mkdir(project_path)\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwYh8sXKHs3O"
   },
   "source": [
    "These paths will be used by the converter script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ABggwdWMGe2h"
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "  os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJpu2BkSUWe4"
   },
   "source": [
    "As an example, we will create and vectorize a few documents. (Check out https://www.gutenberg.org/ for a bunch of free e-books.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in first 1000 sentences from Alice in Wonderland\n",
    "import urllib.request\n",
    "import nltk\n",
    "\n",
    "def read_books(url, starting_sent):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.readlines()\n",
    "    \n",
    "    book = []\n",
    "    read = False # won't start reading until meeting the first sentence in the content\n",
    "    count = 0\n",
    "    for line in data:\n",
    "        line = line.decode('utf-8')\n",
    "        if line.startswith('\\r\\n'):\n",
    "            pass\n",
    "        else:\n",
    "            if line.startswith(starting_sent):\n",
    "                read = True\n",
    "            if read:\n",
    "                count += 1\n",
    "                book.append(line[:-2])\n",
    "    \n",
    "    book = \" \".join(book)   \n",
    "#    sentences = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', book) # split texts into sentences\n",
    "    sentences = nltk.sent_tokenize(book)\n",
    "    if len(sentences) >= 1000:\n",
    "        return sentences[:1000]\n",
    "    else:\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dracula\n",
    "dracula_url = \"http://www.gutenberg.org/cache/epub/345/pg345.txt\"\n",
    "start_line = \"_3 May. Bistritz._--Left Munich at 8:35 P. M., on 1st May\"\n",
    "dracula = read_books(dracula_url, start_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tower of London\n",
    "tower_url = \"https://www.gutenberg.org/files/58271/58271-0.txt\"\n",
    "start_line = \"The Tower of London is the most interesting fortress in Great\"\n",
    "tower_of_london = read_books(tower_url, start_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Blue Jacket\n",
    "jacket_url = \"http://www.gutenberg.org/cache/epub/58270/pg58270.txt\"\n",
    "start_line = \"The big bell of Woolwich Dockyard had just commenced its\"\n",
    "blue_jacket = read_books(jacket_url, start_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books = dracula\n",
    "all_books.extend(tower_of_london)\n",
    "all_books.extend(blue_jacket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = all_books\n",
    "y_train = np.zeros(len(x_train))\n",
    "# 0: Dracula; 1: Tower of London; 2: Blue Jacket\n",
    "y_train[1000:2000] = 1\n",
    "y_train[2000:] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVfStwZCYBAq"
   },
   "source": [
    "Tokenize the documents, create a word index (word -> number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOHTxREVQalF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "max_len = 100\n",
    "num_words = 10000\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# Fit the tokenizer on the training data\n",
    "t = Tokenizer(num_words=num_words)\n",
    "t.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqyqHuLwWT-Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8425"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "feIAyrrxYFoU"
   },
   "source": [
    "Here's how we vectorize a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Jfi7tJbHTwIc"
   },
   "outputs": [],
   "source": [
    "vectorized = t.texts_to_sequences(dracula)\n",
    "# print(vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUfL6MVhYHof"
   },
   "source": [
    "Apply padding if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rbghRbY5QaMV"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded = pad_sequences(vectorized, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xwd6ND_UIKk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1037   95    0 ...    0    0    0]\n",
      " [ 815  201 4086 ...    0    0    0]\n",
      " [2739 2740  582 ...    0    0    0]\n",
      " ...\n",
      " [   8  193  480 ...    0    0    0]\n",
      " [  71  989 8424 ...    0    0    0]\n",
      " [   8  285  158 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9NUXTTuYLZ0"
   },
   "source": [
    "We will save the word index in metadata. Later, we'll use it to convert words typed in the browser to numbers for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UpzusXHhULBr"
   },
   "outputs": [],
   "source": [
    "metadata = {\n",
    "  'word_index': t.word_index,\n",
    "  'max_len': max_len,\n",
    "  'vocabulary_size': num_words,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l57eA3ApZGsC"
   },
   "source": [
    "Define a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLQeTh3uVqtj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 100, 20)           200000    \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 100, 64)           21760     \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 226,995\n",
      "Trainable params: 226,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 20\n",
    "n_classes = 3\n",
    "epochs = 20\n",
    "\n",
    "import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
    "#model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(16, return_sequences=False))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.compile('rmsprop', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VOtCRJiYWZZ"
   },
   "source": [
    "Prepare some training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Q8Y1ZuZYYKC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1037   95    0 ...    0    0    0]\n",
      " [ 815  201 4086 ...    0    0    0]\n",
      " [2739 2740  582 ...    0    0    0]\n",
      " ...\n",
      " [   8  193  480 ...    0    0    0]\n",
      " [  71  989 8424 ...    0    0    0]\n",
      " [   8  285  158 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "x_train = t.texts_to_sequences(x_train)\n",
    "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUWlD3jiX10c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 1.0997 - acc: 0.3263\n",
      "Epoch 2/20\n",
      "3000/3000 [==============================] - 12s 4ms/step - loss: 1.0993 - acc: 0.3140\n",
      "Epoch 3/20\n",
      "3000/3000 [==============================] - 12s 4ms/step - loss: 1.0992 - acc: 0.3297\n",
      "Epoch 4/20\n",
      "3000/3000 [==============================] - 12s 4ms/step - loss: 1.0990 - acc: 0.3360\n",
      "Epoch 5/20\n",
      "3000/3000 [==============================] - 12s 4ms/step - loss: 1.1037 - acc: 0.3407\n",
      "Epoch 6/20\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 1.0992 - acc: 0.3537\n",
      "Epoch 7/20\n",
      "3000/3000 [==============================] - 12s 4ms/step - loss: 1.0993 - acc: 0.3467\n",
      "Epoch 8/20\n",
      "3000/3000 [==============================] - 12s 4ms/step - loss: 1.0978 - acc: 0.3553\n",
      "Epoch 9/20\n",
      "3000/3000 [==============================] - 12s 4ms/step - loss: 1.0817 - acc: 0.4093\n",
      "Epoch 10/20\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 1.0126 - acc: 0.4800\n",
      "Epoch 11/20\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 0.9499 - acc: 0.5013\n",
      "Epoch 12/20\n",
      "3000/3000 [==============================] - 12s 4ms/step - loss: 0.8851 - acc: 0.5433\n",
      "Epoch 13/20\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 0.7875 - acc: 0.5813\n",
      "Epoch 14/20\n",
      "3000/3000 [==============================] - 13s 4ms/step - loss: 0.7360 - acc: 0.5803\n",
      "Epoch 15/20\n",
      "3000/3000 [==============================] - 12s 4ms/step - loss: 0.7746 - acc: 0.5610\n",
      "Epoch 16/20\n",
      "3000/3000 [==============================] - 13s 4ms/step - loss: 0.6939 - acc: 0.6140\n",
      "Epoch 17/20\n",
      "3000/3000 [==============================] - 13s 4ms/step - loss: 0.7011 - acc: 0.6160\n",
      "Epoch 18/20\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 0.6149 - acc: 0.6450\n",
      "Epoch 19/20\n",
      "3000/3000 [==============================] - 13s 4ms/step - loss: 0.5615 - acc: 0.6863\n",
      "Epoch 20/20\n",
      "3000/3000 [==============================] - 13s 4ms/step - loss: 0.5562 - acc: 0.6513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133b372e8>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1YbPNWIenE5"
   },
   "source": [
    "Demo using the model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcmpKvKUY_hK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1037   95  815  201 4086   19 1635 2738  816  471   14 4087   95    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "test_example = \"_3 May. Bistritz._--Left Munich at 8:35 P. M., on 1st May\"\n",
    "x_test = t.texts_to_sequences([test_example])\n",
    "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9dsZSQnrqoU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51712114 0.01563856 0.4672403 ]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "print(preds)\n",
    "print(np.argmax(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-Kuwvqcfptq"
   },
   "source": [
    "Convert the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyo2Q_ehe2RT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved model artifcats in directory: /Users/zy2293/Desktop/ADL4/zy2293.github.io/hw4/model_js\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
    "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
    "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
    "print('\\nSaved model artifcats in directory: %s' % MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z609mw1aj-RJ"
   },
   "source": [
    "Write an index.html and an index.js file configured to load our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IoFAxt8nj9fp"
   },
   "outputs": [],
   "source": [
    "index_html = \"\"\"\n",
    "<!doctype html>\n",
    "\n",
    "<body>\n",
    "  <style>\n",
    "    #textfield {\n",
    "      font-size: 120%;\n",
    "      width: 60%;\n",
    "      height: 200px;\n",
    "    }\n",
    "  </style>\n",
    "  <h1>\n",
    "    Title\n",
    "  </h1>\n",
    "  <hr>\n",
    "  <div class=\"create-model\">\n",
    "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
    "  </div>\n",
    "  <div>\n",
    "    <div>\n",
    "      <span>Vocabulary size: </span>\n",
    "      <span id=\"vocabularySize\"></span>\n",
    "    </div>\n",
    "    <div>\n",
    "      <span>Max length: </span>\n",
    "      <span id=\"maxLen\"></span>\n",
    "    </div>\n",
    "  </div>\n",
    "  <hr>\n",
    "  <div>\n",
    "    <select id=\"example-select\" class=\"form-control\">\n",
    "      <option value=\"example1\">Dracula</option>\n",
    "      <option value=\"example2\">The Tower of London</option>\n",
    "      <option value=\"example3\">Blue Jackets</option>\n",
    "    </select>\n",
    "  </div>\n",
    "  <div>\n",
    "    <textarea id=\"text-entry\"></textarea>\n",
    "  </div>\n",
    "  <hr>\n",
    "  <div>\n",
    "    <span id=\"status\">Standing by.</span>\n",
    "  </div>\n",
    "\n",
    "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
    "  <script src='index.js'></script>\n",
    "</body>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-JsQLbLnkhhk"
   },
   "outputs": [],
   "source": [
    "index_js = \"\"\"\n",
    "const HOSTED_URLS = {\n",
    "  model:\n",
    "      'model_js/model.json',\n",
    "  metadata:\n",
    "      'model_js/metadata.json'\n",
    "};\n",
    "\n",
    "const examples = {\n",
    "  'example1':\n",
    "      '_3 May. Bistritz._--Left Munich at 8:35 P. M., on 1st May.',\n",
    "  'example2':\n",
    "      'The Port of London held a high position from the beginning of the history of Western Europe.',\n",
    "  'example3':\n",
    "      'Clare knew him at once, Crushe having been the second lieutenant of his last ship, and as such having twice endeavoured to get him flogged.'\n",
    "};\n",
    "\n",
    "function status(statusText) {\n",
    "  console.log(statusText);\n",
    "  document.getElementById('status').textContent = statusText;\n",
    "}\n",
    "\n",
    "function showMetadata(metadataJSON) {\n",
    "  document.getElementById('vocabularySize').textContent =\n",
    "      metadataJSON['vocabulary_size'];\n",
    "  document.getElementById('maxLen').textContent =\n",
    "      metadataJSON['max_len'];\n",
    "}\n",
    "\n",
    "function settextField(text, predict) {\n",
    "  const textField = document.getElementById('text-entry');\n",
    "  textField.value = text;\n",
    "  doPredict(predict);\n",
    "}\n",
    "\n",
    "function setPredictFunction(predict) {\n",
    "  const textField = document.getElementById('text-entry');\n",
    "  textField.addEventListener('input', () => doPredict(predict));\n",
    "}\n",
    "\n",
    "function disableLoadModelButtons() {\n",
    "  document.getElementById('load-model').style.display = 'none';\n",
    "}\n",
    "\n",
    "function doPredict(predict) {\n",
    "  const textField = document.getElementById('text-entry');\n",
    "  const result = predict(textField.value);\n",
    "  score_string = \"Class scores: \";\n",
    "  for (var x in result.score) {\n",
    "    score_string += x + \" ->  \" + result.score[x].toFixed(3) + \", \"\n",
    "  }\n",
    "  //console.log(score_string);\n",
    "  status(\n",
    "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
    "}\n",
    "\n",
    "function prepUI(predict) {\n",
    "  setPredictFunction(predict);\n",
    "  const testExampleSelect = document.getElementById('example-select');\n",
    "  testExampleSelect.addEventListener('change', () => {\n",
    "    settextField(examples[testExampleSelect.value], predict);\n",
    "  });\n",
    "  settextField(examples['example1'], predict);\n",
    "}\n",
    "\n",
    "async function urlExists(url) {\n",
    "  status('Testing url ' + url);\n",
    "  try {\n",
    "    const response = await fetch(url, {method: 'HEAD'});\n",
    "    return response.ok;\n",
    "  } catch (err) {\n",
    "    return false;\n",
    "  }\n",
    "}\n",
    "\n",
    "async function loadHostedPretrainedModel(url) {\n",
    "  status('Loading pretrained model from ' + url);\n",
    "  try {\n",
    "    const model = await tf.loadModel(url);\n",
    "    status('Done loading pretrained model.');\n",
    "    disableLoadModelButtons();\n",
    "    return model;\n",
    "  } catch (err) {\n",
    "    console.error(err);\n",
    "    status('Loading pretrained model failed.');\n",
    "  }\n",
    "}\n",
    "\n",
    "async function loadHostedMetadata(url) {\n",
    "  status('Loading metadata from ' + url);\n",
    "  try {\n",
    "    const metadataJson = await fetch(url);\n",
    "    const metadata = await metadataJson.json();\n",
    "    status('Done loading metadata.');\n",
    "    return metadata;\n",
    "  } catch (err) {\n",
    "    console.error(err);\n",
    "    status('Loading metadata failed.');\n",
    "  }\n",
    "}\n",
    "\n",
    "class Classifier {\n",
    "\n",
    "  async init(urls) {\n",
    "    this.urls = urls;\n",
    "    this.model = await loadHostedPretrainedModel(urls.model);\n",
    "    await this.loadMetadata();\n",
    "    return this;\n",
    "  }\n",
    "\n",
    "  async loadMetadata() {\n",
    "    const metadata =\n",
    "        await loadHostedMetadata(this.urls.metadata);\n",
    "    showMetadata(metadata);\n",
    "    this.maxLen = metadata['max_len'];\n",
    "    console.log('maxLen = ' + this.maxLen);\n",
    "    this.wordIndex = metadata['word_index']\n",
    "  }\n",
    "\n",
    "  predict(text) {\n",
    "    // Convert to lower case and remove all punctuations.\n",
    "    const inputText =\n",
    "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
    "    // Look up word indices.\n",
    "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
    "    for (let i = 0; i < inputText.length; ++i) {\n",
    "      const word = inputText[i];\n",
    "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
    "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
    "    }\n",
    "    const input = inputBuffer.toTensor();\n",
    "    //console.log(input);\n",
    "\n",
    "    status('Running inference');\n",
    "    const beginMs = performance.now();\n",
    "    const predictOut = this.model.predict(input);\n",
    "    //console.log(predictOut.dataSync());\n",
    "    const score = predictOut.dataSync();//[0];\n",
    "    predictOut.dispose();\n",
    "    const endMs = performance.now();\n",
    "\n",
    "    return {score: score, elapsed: (endMs - beginMs)};\n",
    "  }\n",
    "};\n",
    "\n",
    "async function setup() {\n",
    "  if (await urlExists(HOSTED_URLS.model)) {\n",
    "    status('Model available: ' + HOSTED_URLS.model);\n",
    "    const button = document.getElementById('load-model');\n",
    "    button.addEventListener('click', async () => {\n",
    "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
    "      prepUI(x => predictor.predict(x));\n",
    "    });\n",
    "    button.style.display = 'inline-block';\n",
    "  }\n",
    "\n",
    "  status('Standing by.');\n",
    "}\n",
    "\n",
    "setup();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KbvVVh1rkmga"
   },
   "outputs": [],
   "source": [
    "with open('index.html','w') as f:\n",
    "  f.write(index_html)\n",
    "  \n",
    "with open('index.js','w') as f:\n",
    "  f.write(index_js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YtvaoazkuRT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index.html       \u001b[34mmodel_js\u001b[m\u001b[m         \u001b[34mzy2293.github.io\u001b[m\u001b[m\r\n",
      "index.js         \u001b[34mpython\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3NX9FVLiBO7"
   },
   "source": [
    "Commit and push everything. Note: we're storing large binary files in GitHub, this isn't ideal (if you want to deploy a model down the road, better to host it in a cloud storage bucket)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RoL5aoRUh5DB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is ahead of 'origin/master' by 6 commits.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Untracked files:\n",
      "\t\u001b[31m../.DS_Store\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git add . \n",
    "!git commit -m \"colab -> github\"\n",
    "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io/ master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDoo_fDVic2E"
   },
   "source": [
    "All done! Hopefully everything worked. You may need to wait a few moments for the changes to appear in your site. If not working, check the JavaScript console for errors (in Chrome: View -> Developer -> JavaScript Console)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1V1QLCxlikOI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, visit https://zy2293.github.io/hw4/\n"
     ]
    }
   ],
   "source": [
    "print(\"Now, visit https://%s.github.io/%s/\" % (USER_NAME, SITE_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mnN6zAHWqPnR"
   },
   "source": [
    "If you are debugging and Chrome is failing to pick up your changes, though you've verified they're present in your GitHub repo, see the second answer to: https://superuser.com/questions/89809/how-to-force-refresh-without-cache-in-google-chrome"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8_colab_to_webpage.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
